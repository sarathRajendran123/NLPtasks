{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00195e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 87339\n",
      "Occurrences of 'race': 0\n",
      "P(race): 0.0\n",
      "Occurrences of 'race' followed by 'NN': 0\n",
      "P(race followed by NN): 0\n",
      "Occurrences of 'race' followed by 'VB': 0\n",
      "P(race followed by VB): 0\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "def count_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "def count_word_occurrences(text, word):\n",
    "    return Counter(text.split())[word]\n",
    "\n",
    "def count_word_followed_by(text, word, next_word):\n",
    "    words = text.split()\n",
    "    count = 0\n",
    "    for i in range(len(words) - 1):\n",
    "        if words[i] == word and i < len(words) - 1 and words[i + 1] == next_word:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def calculate_probability(count_word, total_words):\n",
    "    return count_word / total_words if total_words > 0 else 0\n",
    "\n",
    "file_path = \"shakes.txt\"  \n",
    "\n",
    "text = read_file(file_path)\n",
    "total_words = count_words(text)\n",
    "word = \"race\"\n",
    "word_occurrences = count_word_occurrences(text, word)\n",
    "word1 = \"NN\"\n",
    "word2 = \"VB\"\n",
    "word_followed_by_word1 = count_word_followed_by(text, word, word1)\n",
    "word_followed_by_word2 = count_word_followed_by(text, word, word2)\n",
    "\n",
    "print(f\"Total number of words: {total_words}\")\n",
    "print(f\"Occurrences of '{word}': {word_occurrences}\")\n",
    "print(f\"P({word}): {calculate_probability(word_occurrences, total_words)}\")\n",
    "print(f\"Occurrences of '{word}' followed by '{word1}': {word_followed_by_word1}\")\n",
    "print(f\"P({word} followed by {word1}): {calculate_probability(word_followed_by_word1, word_occurrences)}\")\n",
    "print(f\"Occurrences of '{word}' followed by '{word2}': {word_followed_by_word2}\")\n",
    "print(f\"P({word} followed by {word2}): {calculate_probability(word_followed_by_word2, word_occurrences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d850c6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 87339\n",
      "Occurrences of 'future': 2\n",
      "P(future): 2.2899277527793998e-05\n",
      "Occurrences of 'future' followed by 'NN': 0\n",
      "P(future followed by NN): 0.0\n",
      "Occurrences of 'future' followed by 'VB': 0\n",
      "P(future followed by VB): 0.0\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "def count_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "def count_word_occurrences(text, word):\n",
    "    return Counter(text.split())[word]\n",
    "\n",
    "def count_word_followed_by(text, word, next_word):\n",
    "    words = text.split()\n",
    "    count = 0\n",
    "    for i in range(len(words) - 1):\n",
    "        if words[i] == word and i < len(words) - 1 and words[i + 1] == next_word:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def calculate_probability(count_word, total_words):\n",
    "    return count_word / total_words if total_words > 0 else 0\n",
    "\n",
    "file_path = \"shakes.txt\"  \n",
    "\n",
    "text = read_file(file_path)\n",
    "total_words = count_words(text)\n",
    "word = \"future\"\n",
    "word_occurrences = count_word_occurrences(text, word)\n",
    "word1 = \"NN\"\n",
    "word2 = \"VB\"\n",
    "word_followed_by_word1 = count_word_followed_by(text, word, word1)\n",
    "word_followed_by_word2 = count_word_followed_by(text, word, word2)\n",
    "\n",
    "print(f\"Total number of words: {total_words}\")\n",
    "print(f\"Occurrences of '{word}': {word_occurrences}\")\n",
    "print(f\"P({word}): {calculate_probability(word_occurrences, total_words)}\")\n",
    "print(f\"Occurrences of '{word}' followed by '{word1}': {word_followed_by_word1}\")\n",
    "print(f\"P({word} followed by {word1}): {calculate_probability(word_followed_by_word1, word_occurrences)}\")\n",
    "print(f\"Occurrences of '{word}' followed by '{word2}': {word_followed_by_word2}\")\n",
    "print(f\"P({word} followed by {word2}): {calculate_probability(word_followed_by_word2, word_occurrences)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9650638d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 87339\n",
      "Occurrences of 'this': 426\n",
      "P(this): 0.004877546113420121\n",
      "Occurrences of 'this' followed by 'NN': 0\n",
      "P(this followed by NN): 0.0\n",
      "Occurrences of 'this' followed by 'VB': 0\n",
      "P(this followed by VB): 0.0\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "def count_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "def count_word_occurrences(text, word):\n",
    "    return Counter(text.split())[word]\n",
    "\n",
    "def count_word_followed_by(text, word, next_word):\n",
    "    words = text.split()\n",
    "    count = 0\n",
    "    for i in range(len(words) - 1):\n",
    "        if words[i] == word and i < len(words) - 1 and words[i + 1] == next_word:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def calculate_probability(count_word, total_words):\n",
    "    return count_word / total_words if total_words > 0 else 0\n",
    "\n",
    "file_path = \"shakes.txt\"  \n",
    "\n",
    "text = read_file(file_path)\n",
    "total_words = count_words(text)\n",
    "word = \"this\"\n",
    "word_occurrences = count_word_occurrences(text, word)\n",
    "word1 = \"NN\"\n",
    "word2 = \"VB\"\n",
    "word_followed_by_word1 = count_word_followed_by(text, word, word1)\n",
    "word_followed_by_word2 = count_word_followed_by(text, word, word2)\n",
    "\n",
    "print(f\"Total number of words: {total_words}\")\n",
    "print(f\"Occurrences of '{word}': {word_occurrences}\")\n",
    "print(f\"P({word}): {calculate_probability(word_occurrences, total_words)}\")\n",
    "print(f\"Occurrences of '{word}' followed by '{word1}': {word_followed_by_word1}\")\n",
    "print(f\"P({word} followed by {word1}): {calculate_probability(word_followed_by_word1, word_occurrences)}\")\n",
    "print(f\"Occurrences of '{word}' followed by '{word2}': {word_followed_by_word2}\")\n",
    "print(f\"P({word} followed by {word2}): {calculate_probability(word_followed_by_word2, word_occurrences)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d3a96e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 87339\n",
      "Occurrences of 'love': 304\n",
      "P(love): 0.003480690184224688\n",
      "Occurrences of 'love' followed by 'NN': 0\n",
      "P(love followed by NN): 0.0\n",
      "Occurrences of 'love' followed by 'VB': 0\n",
      "P(love followed by VB): 0.0\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "def count_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "def count_word_occurrences(text, word):\n",
    "    return Counter(text.split())[word]\n",
    "\n",
    "def count_word_followed_by(text, word, next_word):\n",
    "    words = text.split()\n",
    "    count = 0\n",
    "    for i in range(len(words) - 1):\n",
    "        if words[i] == word and i < len(words) - 1 and words[i + 1] == next_word:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def calculate_probability(count_word, total_words):\n",
    "    return count_word / total_words if total_words > 0 else 0\n",
    "\n",
    "file_path = \"shakes.txt\"  \n",
    "\n",
    "text = read_file(file_path)\n",
    "total_words = count_words(text)\n",
    "word = \"love\"\n",
    "word_occurrences = count_word_occurrences(text, word)\n",
    "word1 = \"NN\"\n",
    "word2 = \"VB\"\n",
    "word_followed_by_word1 = count_word_followed_by(text, word, word1)\n",
    "word_followed_by_word2 = count_word_followed_by(text, word, word2)\n",
    "\n",
    "print(f\"Total number of words: {total_words}\")\n",
    "print(f\"Occurrences of '{word}': {word_occurrences}\")\n",
    "print(f\"P({word}): {calculate_probability(word_occurrences, total_words)}\")\n",
    "print(f\"Occurrences of '{word}' followed by '{word1}': {word_followed_by_word1}\")\n",
    "print(f\"P({word} followed by {word1}): {calculate_probability(word_followed_by_word1, word_occurrences)}\")\n",
    "print(f\"Occurrences of '{word}' followed by '{word2}': {word_followed_by_word2}\")\n",
    "print(f\"P({word} followed by {word2}): {calculate_probability(word_followed_by_word2, word_occurrences)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e7edecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 7\n",
      "Occurrences of 'race': 1\n",
      "P(race): 0.14285714285714285\n",
      "Occurrences of 'race' followed by 'NN': 0\n",
      "P(race followed by NN): 0.0\n",
      "Occurrences of 'race' followed by 'VB': 0\n",
      "P(race followed by VB): 0.0\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def count_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "def count_word_occurrences(text, word):\n",
    "    return Counter(text.split())[word]\n",
    "\n",
    "def count_word_followed_by(text, word, next_word):\n",
    "    words = text.split()\n",
    "    count = 0\n",
    "    for i in range(len(words) - 1):\n",
    "        if words[i] == word and i < len(words) - 1 and words[i + 1] == next_word:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def calculate_probability(count_word, total_words):\n",
    "    return count_word / total_words if total_words > 0 else 0\n",
    "\n",
    "sample_text = \"The humans always like to race .\"\n",
    "total_words = count_words(sample_text)\n",
    "word = \"race\"\n",
    "word_occurrences = count_word_occurrences(sample_text, word)\n",
    "word1 = \"NN\"\n",
    "word2 = \"VB\"\n",
    "word_followed_by_word1 = count_word_followed_by(sample_text, word, word1)\n",
    "word_followed_by_word2 = count_word_followed_by(sample_text, word, word2)\n",
    "\n",
    "print(f\"Total number of words: {total_words}\")\n",
    "print(f\"Occurrences of '{word}': {word_occurrences}\")\n",
    "print(f\"P({word}): {calculate_probability(word_occurrences, total_words)}\")\n",
    "print(f\"Occurrences of '{word}' followed by '{word1}': {word_followed_by_word1}\")\n",
    "print(f\"P({word} followed by {word1}): {calculate_probability(word_followed_by_word1, word_occurrences)}\")\n",
    "print(f\"Occurrences of '{word}' followed by '{word2}': {word_followed_by_word2}\")\n",
    "print(f\"P({word} followed by {word2}): {calculate_probability(word_followed_by_word2, word_occurrences)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c28788e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 8\n",
      "Occurrences of 'race': 2\n",
      "P(race): 0.25\n",
      "Occurrences of 'race' followed by 'human': 0\n",
      "P(race followed by human): 0.0\n",
      "Occurrences of 'race' followed by 'like': 0\n",
      "P(race followed by like): 0.0\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def count_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "def count_word_occurrences(text, word):\n",
    "    return Counter(text.split())[word]\n",
    "\n",
    "def count_word_followed_by(text, word, next_word):\n",
    "    words = text.split()\n",
    "    count = 0\n",
    "    for i in range(len(words) - 1):\n",
    "        if words[i] == word and i < len(words) - 1 and words[i + 1] == next_word:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def calculate_probability(count_word, total_words):\n",
    "    return count_word / total_words if total_words > 0 else 0\n",
    "\n",
    "sample_text = \"The human race always like to race .\"\n",
    "total_words = count_words(sample_text)\n",
    "word = \"race\"\n",
    "word_occurrences = count_word_occurrences(sample_text, word)\n",
    "word1 = \"human\"  # Noun\n",
    "word2 = \"like\"   # Verb\n",
    "word_followed_by_word1 = count_word_followed_by(sample_text, word, word1)\n",
    "word_followed_by_word2 = count_word_followed_by(sample_text, word, word2)\n",
    "\n",
    "print(f\"Total number of words: {total_words}\")\n",
    "print(f\"Occurrences of '{word}': {word_occurrences}\")\n",
    "print(f\"P({word}): {calculate_probability(word_occurrences, total_words)}\")\n",
    "print(f\"Occurrences of '{word}' followed by '{word1}': {word_followed_by_word1}\")\n",
    "print(f\"P({word} followed by {word1}): {calculate_probability(word_followed_by_word1, word_occurrences)}\")\n",
    "print(f\"Occurrences of '{word}' followed by '{word2}': {word_followed_by_word2}\")\n",
    "print(f\"P({word} followed by {word2}): {calculate_probability(word_followed_by_word2, word_occurrences)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb40b671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 8\n",
      "Occurrences of 'race': 2\n",
      "P(race): 0.25\n",
      "Occurrences of 'race' followed by a noun: 1\n",
      "P(race followed by a noun): 0.5\n",
      "Occurrences of 'race' followed by a verb: 1\n",
      "P(race followed by a verb): 0.5\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def count_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "def count_word_occurrences(text, word):\n",
    "    return Counter(text.split())[word]\n",
    "\n",
    "def count_word_followed_by(text, word, next_word):\n",
    "    words = text.split()\n",
    "    count = 0\n",
    "    for i in range(len(words) - 1):\n",
    "        if words[i] == word and i < len(words) - 1 and words[i + 1] == next_word:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def calculate_probability(count_word, total_words):\n",
    "    return count_word / total_words if total_words > 0 else 0\n",
    "\n",
    "def identify_part_of_speech(word):\n",
    "    if word.endswith(\"s\"):\n",
    "        return \"noun\"  \n",
    "    else:\n",
    "        return \"verb\"  \n",
    "\n",
    "def count_word_followed_by_part_of_speech(text, word, part_of_speech):\n",
    "    words = text.split()\n",
    "    count = 0\n",
    "    for i in range(len(words) - 1):\n",
    "        if words[i] == word and i < len(words) - 1:\n",
    "            if identify_part_of_speech(words[i + 1]) == part_of_speech:\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "sample_text = \"The human race always wants to race .\"\n",
    "total_words = count_words(sample_text)\n",
    "word = \"race\"\n",
    "word_occurrences = count_word_occurrences(sample_text, word)\n",
    "word1 = \"human\"  # Noun\n",
    "word2 = \"wants\"   # Verb\n",
    "word_followed_by_noun = count_word_followed_by_part_of_speech(sample_text, word, \"noun\")\n",
    "word_followed_by_verb = count_word_followed_by_part_of_speech(sample_text, word, \"verb\")\n",
    "\n",
    "print(f\"Total number of words: {total_words}\")\n",
    "print(f\"Occurrences of '{word}': {word_occurrences}\")\n",
    "print(f\"P({word}): {calculate_probability(word_occurrences, total_words)}\")\n",
    "print(f\"Occurrences of '{word}' followed by a noun: {word_followed_by_noun}\")\n",
    "print(f\"P({word} followed by a noun): {calculate_probability(word_followed_by_noun, word_occurrences)}\")\n",
    "print(f\"Occurrences of '{word}' followed by a verb: {word_followed_by_verb}\")\n",
    "print(f\"P({word} followed by a verb): {calculate_probability(word_followed_by_verb, word_occurrences)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493b550c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe5e1200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouns: ['The', 'human', 'race', 'always', 'like', 'to', 'race.']\n",
      "Verbs: []\n"
     ]
    }
   ],
   "source": [
    "def identify_part_of_speech(word):\n",
    "    # A simple logic to identify if a word is a noun or a verb\n",
    "    # You might want to use a more sophisticated method like a part-of-speech tagger for better accuracy\n",
    "    if word.lower() in [\"i\", \"you\", \"he\", \"she\", \"it\", \"we\", \"they\"]:  # Pronouns\n",
    "        return \"pronoun\"\n",
    "    elif word.endswith(\"s\"):\n",
    "        return \"noun\"  # Assuming plural nouns end with \"s\"\n",
    "    elif word.endswith(\"ing\"):\n",
    "        return \"verb\"  # Assuming verbs in gerund form end with \"ing\"\n",
    "    elif word.endswith(\"ed\"):\n",
    "        return \"verb\"  # Assuming verbs in past tense end with \"ed\"\n",
    "    elif word.endswith(\"es\"):\n",
    "        return \"verb\"  # Assuming verbs in third person singular present tense end with \"es\"\n",
    "    else:\n",
    "        return \"noun\"  # Default to noun\n",
    "\n",
    "def find_nouns_and_verbs(sentence):\n",
    "    words = sentence.split()\n",
    "    nouns = []\n",
    "    verbs = []\n",
    "    for word in words:\n",
    "        if identify_part_of_speech(word) == \"noun\":\n",
    "            nouns.append(word)\n",
    "        elif identify_part_of_speech(word) == \"verb\":\n",
    "            verbs.append(word)\n",
    "    return nouns, verbs\n",
    "\n",
    "# Sample sentence\n",
    "sentence = \"The human race always like to race.\"\n",
    "nouns, verbs = find_nouns_and_verbs(sentence)\n",
    "\n",
    "print(\"Nouns:\", nouns)\n",
    "print(\"Verbs:\", verbs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0ff8b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbs: ['wants']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "def find_verbs(sentence):\n",
    "    # Tokenize the sentence into words\n",
    "    words = word_tokenize(sentence)\n",
    "    # Perform part-of-speech tagging\n",
    "    tagged_words = pos_tag(words)\n",
    "    # Filter out verbs (VB* tags)\n",
    "    verbs = [word for word, tag in tagged_words if tag.startswith('VB')]\n",
    "    return verbs\n",
    "\n",
    "# Sample sentence\n",
    "sentence = \"The human race always wants to race.\"\n",
    "verbs = find_verbs(sentence)\n",
    "\n",
    "print(\"Verbs:\", verbs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624d667c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa05fc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 22\n",
      "Occurrences of 'race': 4\n",
      "P(race): 0.18181818181818182\n",
      "Occurrences of 'race' followed by a noun: 3\n",
      "P(race followed by a noun): 0.75\n",
      "Occurrences of 'race' followed by a verb: 1\n",
      "P(race followed by a verb): 0.25\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def count_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "def count_word_occurrences(text, word):\n",
    "    return Counter(text.split())[word]\n",
    "\n",
    "def count_word_followed_by_part_of_speech(text, word, part_of_speech):\n",
    "    words = text.split()\n",
    "    count = 0\n",
    "    for i in range(len(words) - 1):\n",
    "        if words[i] == word and i < len(words) - 1:\n",
    "            if identify_part_of_speech(words[i + 1]) == part_of_speech:\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "def calculate_probability(count_word, total_words):\n",
    "    return count_word / total_words if total_words > 0 else 0\n",
    "\n",
    "def identify_part_of_speech(word):\n",
    "    if word.lower() in [\"i\", \"you\", \"he\", \"she\", \"it\", \"we\", \"they\"]:  # Pronouns\n",
    "        return \"pronoun\"\n",
    "    elif word.endswith(\"s\"):\n",
    "        return \"verb\"  # Assuming plural nouns end with \"s\"\n",
    "    elif word.endswith(\"ing\"):\n",
    "        return \"verb\"  # Assuming verbs in gerund form end with \"ing\"\n",
    "    elif word.endswith(\"ed\"):\n",
    "        return \"verb\"  # Assuming verbs in past tense end with \"ed\"\n",
    "    elif word.endswith(\"es\"):\n",
    "        return \"verb\"  # Assuming verbs in third person singular present tense end with \"es\"\n",
    "    else:\n",
    "        return \"noun\"  # Default to noun\n",
    "\n",
    "sample_text = \"The human race always wants to race . The race began at dawn . He won the swimming race with ease .\"\n",
    "total_words = count_words(sample_text)\n",
    "word = \"race\"\n",
    "word_occurrences = count_word_occurrences(sample_text, word)\n",
    "word_followed_by_noun = count_word_followed_by_part_of_speech(sample_text, word, \"noun\")\n",
    "word_followed_by_verb = count_word_followed_by_part_of_speech(sample_text, word, \"verb\")\n",
    "\n",
    "print(f\"Total number of words: {total_words}\")\n",
    "print(f\"Occurrences of '{word}': {word_occurrences}\")\n",
    "print(f\"P({word}): {calculate_probability(word_occurrences, total_words)}\")\n",
    "print(f\"Occurrences of '{word}' followed by a noun: {word_followed_by_noun}\")\n",
    "print(f\"P({word} followed by a noun): {calculate_probability(word_followed_by_noun, word_occurrences)}\")\n",
    "print(f\"Occurrences of '{word}' followed by a verb: {word_followed_by_verb}\")\n",
    "print(f\"P({word} followed by a verb): {calculate_probability(word_followed_by_verb, word_occurrences)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b72ccb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\win10\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\treebank.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('treebank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1ec2340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('cat', 'NNP'), ('sat', 'NNP'), ('on', 'NNP'), ('the', 'NNP'), ('mat', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tag import hmm\n",
    "\n",
    "tagged_corpus = nltk.corpus.treebank.tagged_sents()[:500]\n",
    "\n",
    "trainer = hmm.HiddenMarkovModelTrainer()\n",
    "hmm_tagger = trainer.train(tagged_corpus)\n",
    "\n",
    "sent = \"The cat sat on the mat\".split()\n",
    "tagged_sent = hmm_tagger.tag(sent)\n",
    "print(tagged_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81584947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
